---
title: "Survival Semiparametric"
format:
  html:
    theme: sketchy
    fontsize: 1.1em
    linestretch: 1.5
    toc: true
    toc-location: left-body
    toc-depth: 2
    number-sections: true
    number-depth: 3
---

<img src="members.png" style="border-radius: 15px; display: block; margin: auto;" width="400px"/>

# Load packages

```{r}
library(haven)
library(survival)
library(survminer)
library(dplyr)
library(broom)
library(tidyverse)
library(gtsummary)
library(ggplot2)
library(corrplot)
```

# Load dataset

```{r}
data1 <- read_dta("stroke_fatality.dta")

# View structure
str(data1)

# View the first few rows
head(data1)

# Quick summary
summary(data1)

data1 %>% 
  tbl_summary()
```

The initial dataset comprised 226 observations with 49 variables related to sociodemographic, clinical, and laboratory information of stroke patients.

Upon exploration using the `str()` and `summary()` functions, several variables were identified to contain suspicious or non-informative coding (e.g., 8, 9) or even excessive missingness.

# Handling missing data

## Visualising the problematic data

```{r}
library(naniar)

# Bar plot: Proportion of missing data by variable
# Naniar bar plot
gg_miss_var(data1) +
  ggtitle("Proportion of Missing Data by Variable")
```

A bar chart using the `gg_miss_var()` function from the `naniar` package was employed to visualize the proportion of missing data by variable.

This revealed that several variables, particularly laboratory values like cholesterol and triglycerides, had high missingness (often \>80%).

## Summarizing the problematic data for variable selection decision

```{r}
# function for numerical data

summarize_data_quality <- function(data, round_digits = 2) {
  if (!requireNamespace("dplyr")) install.packages("dplyr")
  if (!requireNamespace("tidyr")) install.packages("tidyr")
  library(dplyr)
  library(tidyr)
  
  # Step 1: Missing count and percent
  missing_summary <- data %>%
    summarise(across(everything(), ~sum(is.na(.)))) %>%
    pivot_longer(cols = everything(), names_to = "Variable", values_to = "Missing_Count") %>%
    mutate(Total = nrow(data),
           Missing_Percent = round((Missing_Count / Total) * 100, round_digits))  # Rounded %
  
  # Step 2: Descriptive summary (numeric only)
  summary_stats <- data %>%
    select(where(is.numeric)) %>%
    summarise(across(everything(), list(
      count = ~sum(!is.na(.)),
      mean = ~round(mean(., na.rm = TRUE), round_digits),
      sd = ~round(sd(., na.rm = TRUE), round_digits),
      min = ~round(min(., na.rm = TRUE), round_digits),
      q25 = ~round(quantile(., 0.25, na.rm = TRUE), round_digits),
      median = ~round(median(., na.rm = TRUE), round_digits),
      q75 = ~round(quantile(., 0.75, na.rm = TRUE), round_digits),
      max = ~round(max(., na.rm = TRUE), round_digits)
    ), .names = "{.col}_{.fn}")) %>%
    pivot_longer(cols = everything(),
                 names_to = c("Variable", ".value"),
                 names_sep = "_")
  
  # Step 3: Merge + final polish
  summary_table <- left_join(missing_summary, summary_stats, by = "Variable") %>%
    mutate(
      Action = case_when(
        Missing_Percent > 80 ~ "Drop (>80% missing)",
        Missing_Percent > 0 ~ "Consider imputing",
        TRUE ~ "Keep"
      ),
      MaxFlag = ifelse(!is.na(max) & max > 2, "Check coding (>2)", "")
    ) %>%
    arrange(desc(Missing_Percent)) %>%
    rename(`Missing %` = Missing_Percent)
  
  return(summary_table)
}


# function for categorical data

view_categorical_labels <- function(data) {
  cat_vars <- names(data)[sapply(data, function(x) {
    is.factor(x) || is.character(x) || ("labels" %in% names(attributes(x)))
  })]
  
  for (var in cat_vars) {
    cat("\n============================\n")
    cat("ðŸ“Œ Variable:", var, "\n")
    
    var_data <- data[[var]]

    # Show value labels if exist
    label_attr <- attributes(var_data)$labels
    if (!is.null(label_attr)) {
      cat("ðŸ”– Value Labels:\n")
      print(label_attr)
    }
    
    # Show levels if factor or character
    if (is.factor(var_data) || is.character(var_data)) {
      cat("ðŸ“Š Levels / Unique Values:\n")
      print(levels(as.factor(var_data)))
    }

    # Frequency Table using as_factor for haven_labelled
    cat("ðŸ“ˆ Frequency Table:\n")
    freq_table <- table(as_factor(var_data), useNA = "ifany")
    print(freq_table)

    # Auto-check for suspicious codes
    suspicious_codes <- c(8, 9, 88, 99, 888, 999, 8888, 9999)
    numeric_data <- suppressWarnings(as.numeric(as.character(var_data)))
    invalids <- intersect(suspicious_codes, unique(na.omit(numeric_data)))
    
    if (length(invalids) > 0) {
      cat("ðŸš¨ Warning: Suspicious codes detected -> ", paste(invalids, collapse = ", "), "\n")
    }
  }
}
```

```{r}
# Summarize the dataset via the functions

summary_data1 <- summarize_data_quality(data1)

# View it
View(summary_data1)

# categorical data
view_categorical_labels(data1)
```

In this analysis, we selected variables based on a combination of:

1.   **Clinical relevance** to stroke fatality, as reported in prior studies, particularly the multicenter prospective cohort by **Sarfo et al. (2023)**, which highlighted both patient-level and system-level determinants.

    References: Sarfo, Fred S., et al. "Determinants of stroke fatality in sub-Saharan Africa: a multicenter prospective cohort study." *Lancet Global Health*, 2023.

2.  **Data completeness**, to ensure robust and reliable model estimation.

In term of data completeness, a structured summary of missingness and descriptive statistics was generated using custom functions. Categorical variables were inspected for value label inconsistencies, while numeric variables were assessed for completeness and distribution.

Several variables, such as `dm`, `hpt`, `ckd`, and `smoker`, contained suspicious codes (e.g., 8) representing non-standard or unknown values, which required recoding.

Based on this analysis, variables with high missingness or problematic coding were excluded from the final model.

However, gcs variable is clinically important, but had 0.44% missingness of data. hence, we consider this variable to be imputed and included in the model as well.

```{r}
# impute missing data for gcs variable

median_gcs <- median(data1$gcs, na.rm = TRUE)
data1$gcs[is.na(data1$gcs)] <- median_gcs

```

## Cleaning the problematic dataset for analysis (select variables that already been re-coded appropriately)

```{r}
library(dplyr)

# Create cleaned dataset
data2 <- data1 %>%
  select(
    time2, status3b, age2, sex3, gcs, hpt2cat, dm2cat, dyslipid2cat,
    referral2cat, icd10cat3
  )

glimpse(data2)
```

A cleaned dataset (`data2`) was created by selecting only variables that had already been appropriately recoded.

The chosen variables were `time2`, `status3b` (event indicator), `age2`, `sex3`, `hpt2cat`, `dm2cat`, `dyslipid2cat`, `referral2cat`, and `icd10cat3`.

This step ensured the inclusion of well-defined, binary or categorical predictors and improved the quality and interpretability of the analysis.

# Summarizing and visualising the cleaned dataset

```{r}
# Run the summarize function

summary_data2 <- summarize_data_quality(data2)

# View it
View(summary_data2)

view_categorical_labels(data2)
```

```{r}
library(ggplot2)
library(dplyr)
library(forcats)

# Barplot : status3b

data2 %>%
  mutate(
    status3b = case_when(
      status3b == 0 ~ "Alive",
      status3b == 1 ~ "Dead",
      TRUE ~ NA_character_
    )
  ) %>%
  ggplot(aes(x = status3b, fill = status3b)) +
  geom_bar() +
  labs(title = "Distribution of Survival Status",
       x = "Status at Discharge", y = "Count") +
  theme_minimal() +
  scale_fill_manual(values = c("Alive" = "#4CAF50", "Dead" = "#F44336"))
```

```{r}
# Barplot : sex

data2 %>%
  mutate(sex3 = factor(sex3, levels = c(0,1), labels = c("Female", "Male"))) %>%
  ggplot(aes(x = sex3, fill = sex3)) +
  geom_bar() +
  labs(title = "Sex Distribution", x = "Sex", y = "Count") +
  theme_minimal() +
  scale_fill_manual(values = c("#FF69B4", "#2196F3"))
```

```{r}
# Barplot : icd10cat3

data2 %>%
  mutate(icd10cat3 = factor(icd10cat3,
                            levels = c(0,1,2),
                            labels = c("Cerebral Ischaemia", "SAH", "ICB/Others"))) %>%
  ggplot(aes(x = icd10cat3, fill = icd10cat3)) +
  geom_bar() +
  labs(title = "Stroke Subtype Distribution", x = "Stroke Type", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")
```

```{r}
# Barplot : referral2cat

data2 %>%
  mutate(referral2cat = factor(referral2cat,
                               levels = c(0, 1),
                               labels = c("Hospital", "GP/Home/Missing"))) %>%
  ggplot(aes(x = referral2cat, fill = referral2cat)) +
  geom_bar() +
  labs(title = "Referral Source", x = "Referral Category", y = "Count") +
  theme_minimal() +
  scale_fill_manual(values = c("#03A9F4", "#FFC107"))
```

Descriptive statistics and frequency tables were produced for the cleaned dataset.

Among the 226 patients, 53 deaths were observed (23.5%). The majority were females (57.1%) and had cerebral ischaemic stroke. Most referrals originated from home or private clinics (61.5%).

These characteristics provided an overview of the study population before proceeding with model fitting.

## Convert the cleaned data to appropriate types

```{r}
data3 <- data2 %>%
  mutate(
    status3b = as.numeric(zap_labels(status3b)), 
    sex3 = as.factor(sex3),
    gcs = as.numeric(gcs),
    hpt2cat = as.factor(hpt2cat),
    dm2cat = as.factor(dm2cat),
    dyslipid2cat = as.factor(dyslipid2cat),
    referral2cat = as.factor(referral2cat),
    icd10cat3 = as.factor(icd10cat3)
  )

```

Prior to modeling, variables were converted to appropriate types.

Categorical variables were converted to factors and the outcome variable (status3b) was transformed into a numeric binary indicator (0 = alive, 1 = dead). This is essential for ensuring compatibility with the Cox proportional hazards model.

```{r}
data3 %>% 
  tbl_summary()
```

# Create Survival Object

```{r}
surv_obj <- Surv(time = data3$time2, event = data3$status3b)
```

A survival object was created using the `Surv()` function, which combines the time-to-event (`time2`) and event status (`status3b`) variables.

This served as the basis for fitting the semiparametric Cox model and for plotting survival curves.

# Kaplan-Meir survical estimates for overall

```{r}
KM1 <- survfit(surv_obj ~ 1)
summary(KM1)
```

The overall Kaplan-Meier survival curve revealed a **gradual decline in survival probability over time**, as expected in a hospital-based cohort of stroke patients.

At **Day 1**, the estimated survival probability was **94.2%** (95% CI: 91.3%â€“97.3%), with 13 events (deaths) observed. By **Day 5**, survival dropped to **82.7%** (95% CI: 76.9%â€“88.9%), and by **Day 10**, it further declined to **68.3%** (95% CI: 59.4%â€“78.7%).

By **Day 22**, the survival probability was **49.4%** (95% CI: 37.6%â€“64.9%), indicating that nearly half of the cohort had experienced the event (death) or were censored by this time point. The survival probability continued to decline steadily over time, reaching **17.6%** (95% CI: 6.1%â€“50.9%) at Day 41.

The increasing standard error and widening confidence intervals over time reflect a **decrease in the number of patients at risk**, leading to more uncertainty in the later estimates.

# Kaplan-Meier estimates for groups

## 1. Sex

```{r}
# KM estimates

KM1_sex <- survfit(surv_obj ~ sex3, data = data3)
summary(KM1_sex)
```

```{r}
# plot

library(survminer)

ggsurvplot(KM1_sex, data = data3, pval = TRUE, risk.table = TRUE,
           legend.title = "Sex", 
           title = "Kaplan-Meier Survival by Sex",
           xlab = "Days", ylab = "Survival Probability")
```

## 2. Diabetes Mellitus

```{r}
KM1_dm <- survfit(surv_obj ~ dm2cat, data = data3)
summary(KM1_dm)
```

```{r}
ggsurvplot(KM1_dm, data = data3, pval = TRUE, risk.table = TRUE,
           legend.title = "DM", 
           title = "Kaplan-Meier Survival by DM",
           xlab = "Days", ylab = "Survival Probability")
```

## 3. Hypertension

```{r}
KM1_hpt <- survfit(surv_obj ~ hpt2cat, data = data3)
summary(KM1_hpt)
```

```{r}
ggsurvplot(KM1_hpt, data = data3, pval = TRUE, risk.table = TRUE,
           legend.title = "Hpt", 
           title = "Kaplan-Meier Survival by HPT",
           xlab = "Days", ylab = "Survival Probability")
```

## 4. Dyslipidaemia

```{r}
KM1_dys <- survfit(surv_obj ~ dyslipid2cat, data = data3)
summary(KM1_dys)
```

```{r}
ggsurvplot(KM1_dys, data = data3, pval = TRUE, risk.table = TRUE,
           legend.title = "Dyslipid", 
           title = "Kaplan-Meier Survival by Dyslipid",
           xlab = "Days", ylab = "Survival Probability")
```

## 5. Referral

```{r}
KM1_ref <- survfit(surv_obj ~ referral2cat, data = data3)
summary(KM1_ref)
```

```{r}
ggsurvplot(KM1_ref, data = data3, pval = TRUE, risk.table = TRUE,
           legend.title = "Referral", 
           title = "Kaplan-Meier Survival by Referral",
           xlab = "Days", ylab = "Survival Probability")
```

## 6. ICD10

```{r}
KM1_icd10 <- survfit(surv_obj ~ icd10cat3, data = data3)
summary(KM1_icd10)
```

```{r}
ggsurvplot(KM1_ref, data = data3, pval = TRUE, risk.table = TRUE,
           legend.title = "ICD10", 
           title = "Kaplan-Meier Survival by ICD10",
           xlab = "Days", ylab = "Survival Probability")
```

# Estimate Survival Probabilities

Estimation of the survival probabality at that specific time of follow-up:

```{r}
data3 %>% group_by(status3b) %>%    
  summarize(min.dur = min(time2), max.dur = max(time2))
```

```{r}
summary(KM1, times = c(20, 40, 60))
```

Comparing the survival estimates between levels of a group (categorical) variable Log Rank Test

The null hypothesis : survival estimates between levels or groups are not different.

## 1. Sex

```{r}
logrank.sex <- survdiff(Surv(time = time2, event = status3b) ~ sex3, 
                        data = data3, rho = 0)
logrank.sex


```

The survival estimates between the gender group are not different( p value : 0.2)

## 2. DM

```{r}
logrank.dm <- survdiff(Surv(time = time2, event = status3b) ~ dm2cat, 
                        data = data3, rho = 0)
logrank.dm
```

The survival estimates between the DM status are not different (p value : 0.1)

## 3. Hypertension

```{r}
logrank.hpt <- survdiff(Surv(time = time2, event = status3b) ~ hpt2cat, 
                        data = data3, rho = 0)
logrank.hpt
```

The survival estimates between the hpt status are not different (p value : 0.9)

## 4. Dyslipidaemia

```{r}
logrank.dys <- survdiff(Surv(time = time2, event = status3b) ~ dyslipid2cat, 
                        data = data3, rho = 0)
logrank.dys
```

The survival estimates between the dyslipidaemia status are not different (p value : 0.1)

## 5. Referral

```{r}
logrank.ref <- survdiff(Surv(time = time2, event = status3b) ~ referral2cat, 
                        data = data3, rho = 0)
logrank.ref
```

The survival estimates between the dyslipidaemia status are not different (p value : 0.08)

## 6. ICD10

```{r}
logrank.icd10 <- survdiff(Surv(time = time2, event = status3b) ~ icd10cat3, 
                        data = data3, rho = 0)
logrank.icd10
```

The survival estimates between stroke type ( CI, SAH, ICB and others ) are different at the level of 5% significance (p-value = 0.03).

# Fit Cox Proportional Hazard Model (Semi-parametic)

## Univariable Simple Cox PH Regression

## 1. GCS

```{r}
cox.gcs <- coxph(Surv(time = time2, event = status3b) ~ gcs, data = data3)
summary(cox.gcs)

```

The simple cox PH model with covariate gcs shows that with each one unit increase in gcs, the crude log hazard for death changes by factor of -0.185.

The p-value is significant.

Exponentiating the log HR, the simple cox shows that with increase one unit of gcs, the crude risk for death decreases for about 17% and the decrease are between 95% CI ( 0.78, 0.88).

## 2. Age

```{r}
cox.age <- coxph(Surv(time = time2, event = status3b) ~ age2, data = data3)
summary(cox.age)
```

The simple cox PH model with covariate age shows that with each one unit increase in age, the crude log hazard for death changes by factor of 1.025.

## 3. Sex

```{r}
cox.sex <- coxph(Surv(time = time2, event = status3b) ~ sex3, data = data3)
summary(cox.sex)
```

in simple cox PH regression , the covariate sex is not significant ( p-value 0.171)

## 4. ICD10

```{r}
cox.icd10 <- coxph(Surv(time = time2, event = status3b) ~ icd10cat3, data = data3)
summary(cox.icd10)
```

```{r}
tidy(cox.icd10,     exponentiate = TRUE,      conf.int = TRUE)
```

The simple Cox PH model with covariate stroke type shows that patients with haemorhagic stroke has the crude log hazard for death 2.27 times compared to patients with ischaemic type (p-value = 0.04, 95% CI 1.02, 5.07) and 2.19 times compared to patients with SAH type (p-value = 0.02, 95% CI 1.15, 4.14)

## 5. Hypertension

```{r}
cox.hpt <- coxph(Surv(time = time2, event = status3b) ~ hpt2cat, data = data3)
summary(cox.hpt)
```

for hypertension status, the covariate is not significant.

## 6. Dyslipidaemia

```{r}
cox.dys <- coxph(Surv(time = time2, event = status3b) ~ dyslipid2cat, data = data3)
summary(cox.dys)
```

for dyslipidaemia status, the covariate is not significant.

## 7. Diabetes Mellitus

```{r}
cox.dm <- coxph(Surv(time = time2, event = status3b) ~ dm2cat, data = data3)
summary(cox.dm)
```

for DM status , the covariate is not significant.

## 8. Referral

```{r}
cox.ref <- coxph(Surv(time = time2, event = status3b) ~ referral2cat, data = data3)
summary(cox.ref)
```

for referral status , the covariate is not significant.

# Multivariable Cox PH

## Main Effect Model

```{r}
cox_model <- coxph(surv_obj ~ age2 + gcs + icd10cat3, data = data3)
summary(cox_model)
```

-   The model is statistically significant (**LR test p \< 0.0001**), and explains survival well (**C = 0.812**).

    **Older age** and **lower GCS** are independently associated with higher mortality among stroke patients.

    For each additional year of age, the hazard of death increases by 3.3%. Age is a significant risk factor.

    For each 1-point increase in GCS, the hazard of death decreases by 16.7%. GCS is a **protective factor** and highly significant.

    While the ICD-10 category showed elevated hazard ratios, the wide confidence intervals and non-significant p-values suggest **uncertainty in their effects** in this sample size.

## Model with interaction

Numerical and Numerical

```{r}
cox_gcs.age <- coxph(surv_obj ~ age2 + gcs + icd10cat3 + gcs*age2, data = data3)
summary(cox_gcs.age)
```

Numerical and Categorical

```{r}
cox_gcs.icd10 <- coxph(surv_obj ~ age2 + gcs + icd10cat3 + gcs*icd10cat3, data = data3)
summary(cox_gcs.icd10)
```

# Model Comparison

```{r}
anova(cox_model, cox_gcs.age)
```

```{r}
anova(cox_model, cox_gcs.icd10)
```

Although the interaction model (age, GCS, and stroke subtype with GCS Ã— subtype interaction) showed a statistically significant improvement in fit (p = 0.009), we retained the main effects model based on the principle of **parsimony**.

This simpler model is more interpretable and avoids potential overfitting, especially given the limited number of events (n = 53). Including interaction terms may complicate clinical interpretation without substantial added benefit.

The final model retained variables with clear clinical relevance and demonstrated good concordance (0.812), supporting its predictive validity.

# Model Checking Plotting Kaplan-Meier

1.  Linearity in hazard assumption For numerical

Age2 and gcs

```{r}
data4 <- data3[complete.cases(data3[, c("time2", "status3b", "age2", "gcs")]), ] 
```

```{r}
ggcoxfunctional(Surv(time2, status3b) ~ age2 + gcs, data = data4)
```

Linearity assummed

# Propotional Hazard Assumption

The main assumption in Cox PH regression is that the estimated hazard is proportional across the follow-up time.

1.  KM Method

```{r}
prop.h.km <- cox.zph(cox_model, transform = 'km', global = TRUE) 
prop.h.km
```

```{r}
plot(prop.h.km)
```

2.  The Rank Method

```{r}
prop.h.rank <- cox.zph(cox_model, transform = 'rank') 
prop.h.rank
```

```{r}
plot(prop.h.rank)
```

# Model Checking

Final model : cox_model

1.  Residuals

We can use residuals to assess for model fitness. They are useful to check for overall model fitness or for individual subjects fitness. The residuals can indicate the presence of outliers or influential subjects in our model.

residuals can be calculated to produce martingale, deviance, score or Schoenfeld residuals for a Cox proportional hazards model.

1.1 Score Residuals

```{r}
score.cox <- resid(cox_model, type = "score") 
head(score.cox)
```

1.2 Martingale residuals

```{r}
marti.cox <- resid(cox_model, type = "martingale") 
head(marti.cox)
```

1.3 Schoenfeld residuals

```{r}
schoen.cox <- resid(cox_model, type = "schoenfeld") 
head(schoen.cox)
```

1.4 Scaled Schoenfeld residuals

```{r}
sschoen.cox <- resid(cox_model, type = "scaledsch") 
head(sschoen.cox)
```

1.5 dfbeta

```{r}
dfbeta.cox <- resid(cox_model, type = "dfbeta") 
head(dfbeta.cox)
```

2.  Residual Plot Plot to identify the outliers using score residuals

```{r}
plot(data4$gcs, score.cox[,2], ylab="Score residuals")
```

```{r}
plot(data4$age2, score.cox[,1], ylab="Score residuals")
```

Plot to identify the outliers using martingale residuals

```{r}
plot(data4$age2, marti.cox, ylab = "Martingale residuals for age")
```

```{r}
plot(marti.cox, type = 'h', main = "Martingale residuals", ylab = "dfbetas")
```

Or , we use the augment() function to do similar tasks as above. The resulting datasets consists of - the fitted variable

-   the std error of the fitted variable

-   the residuals

```{r}
pred.cox_model <- augment(cox_model, data = data4) 
pred.cox_model
```

# Prediction

From the Cox PH , we can predict:

1\. The linear predictor

2\. The risk

3\. The expected number of events given the covariates and follow up time

We make a new data and name them as newdata using expand.grid() function:

Our final model

```{r}
cox_model <- coxph(surv_obj ~ age2 + gcs + icd10cat3, data = data4)

summary(cox_model)
```

```{r}
tidy(cox_model)
```

```{r}
data4 %>% 
  select(gcs, age2, icd10cat3) %>% 
  summary()
```

```{r}
new_data <- expand.grid(
  gcs = c(5, 10, 12),
  age2 = c(40, 50, 60),
  icd10cat3 = c("0", "1", "2")
)

new_data

```

# Linear Predictor

Model : cox_model

```{r}
predict(cox_model, newdata = new_data, type = 'lp')
```

```{r}
augment(cox_model, newdata = new_data)
```

Manual calculation :

```{r}
predict(cox_model, newdata = new_data, type = 'lp')
```

```{r}
new_data[1,]
```

```{r}
# Step 1: Pull coefficients
b_age  <- coef(cox_model)["age2"]
b_gcs  <- coef(cox_model)["gcs"]

# Step 2: Get means
mean_age <- mean(data4$age2, na.rm = TRUE)
mean_gcs <- mean(data4$gcs, na.rm = TRUE)

# Step 3: Center your values
gcs.c <- 5 - mean_gcs
age.c <- 40 - mean_age

# Step 4: Calculate LP
lp <- (b_gcs * gcs.c) + (b_age * age.c)
lp
```

For this patient, The value `0.6899` is the **log hazard** which translate into 1.99 when exponentiated.

Hence, he has an estimated hazard of death that is approximately **1.99 times higher** than a hypothetical baseline patient (when the variables are mean values)

# Risk score

```{r}
predict(cox_model, newdata = new_data, type = 'risk')
```

Each value reflects the **log hazard** for an individual patient based on the modelâ€™s covariates (`age2`, `gcs`, `icd10cat3`). Higher scores imply **greater predicted risk of death** during follow-up.

for example, patient 16 has highest predicted risk â€” this patient likely had very low GCS, older age, and hemorrhagic stroke. Critical monitoring or palliative care might be warranted.

pected number of events for a given follow-up time

Let us set the event = 1 and follow-up time = 1878 days

```{r}
cox_model <- coxph(Surv(time2, status3b) ~ age2 + gcs + icd10cat3, data = data3)

```

```{r}
library(tidyr)

# Reuse same levels for factor variable
data3$icd10cat3 <- factor(data3$icd10cat3)
levels_icd10 <- levels(data3$icd10cat3)

# Expand combinations
new_data3 <- crossing(
  gcs = c(5, 10, 12),
  age2 = c(40, 50, 60),
  icd10cat3 = factor(c(0, 1, 2), levels = levels_icd10),
  time2 = c(20, 40, 50),
  status3b = 1
)

```

```{r}
pred.exp <- predict(cox_model, newdata = new_data3, type = "expected")
cbind(new_data3, pred.exp)


```

Based on the fitted Cox model, the expected number of events (deaths) increases with **longer follow-up duration**, **worsening stroke subtype**, and **increasing age**. Patients with **SAH or ICB** exhibit **higher cumulative hazards**, particularly beyond **day 40**, compared to those with ischaemic stroke.

This analysis allows **personalized prediction** of risk and can inform **clinical decision-making**, especially for **early intervention**, **ICU triage**, or **family counseling**.

## Conclusion

In conclusion, the establishment of this surival semiparametric model enables **individualized prognostic insights** tailored to a patientâ€™s profile, which can supports **clinical decision-making** and priority setting, especially for follow-up care or palliative discussions. Besides, it also can enhances **patientâ€“clinician communication** by providing quantifiable risk trajectories. In summary, it can provide a valuable tool for **evidence-based, patient-centered care** in stroke management itself.

# Github link

<https://github.com/Aina0710/DrPH1_SEM_2/tree/main>
