---
title: "Final Survival Semiparametric"
author: "Amin Aina Shu"
format: html
editor: visual
---

## Checking the dataset

```{r}
library(haven)
library(survival)
library(survminer)
library(dplyr)

data1 <- read_dta("C:/Users/amin9/OneDrive/R working directory/assignment prof kim drph1 sem 2/survival/semiparametric/stroke_fatality.dta")

# View structure
str(data1)

# View the first few rows
head(data1)

# Quick summary
summary(data1)
```

The initial dataset comprised 226 observations with 49 variables related to sociodemographic, clinical, and laboratory information of stroke patients.

Upon exploration using the `str()` and `summary()` functions, several variables were identified to contain suspicious or non-informative coding (e.g., 8, 9) or even excessive missingness.

## Visualising the problematic data

```{r}
library(naniar)

# Bar plot: Proportion of missing data by variable
# Naniar bar plot
gg_miss_var(data1) +
  ggtitle("Proportion of Missing Data by Variable")
```

A bar chart using the `gg_miss_var()` function from the `naniar` package was employed to visualize the proportion of missing data by variable.

This revealed that several variables, particularly laboratory values like cholesterol and triglycerides, had high missingness (often \>80%).

## Summarizing the problematic data for decision

```{r}
# function for numerical data

summarize_data_quality <- function(data, round_digits = 2) {
  if (!requireNamespace("dplyr")) install.packages("dplyr")
  if (!requireNamespace("tidyr")) install.packages("tidyr")
  library(dplyr)
  library(tidyr)
  
  # Step 1: Missing count and percent
  missing_summary <- data %>%
    summarise(across(everything(), ~sum(is.na(.)))) %>%
    pivot_longer(cols = everything(), names_to = "Variable", values_to = "Missing_Count") %>%
    mutate(Total = nrow(data),
           Missing_Percent = round((Missing_Count / Total) * 100, round_digits))  # Rounded %
  
  # Step 2: Descriptive summary (numeric only)
  summary_stats <- data %>%
    select(where(is.numeric)) %>%
    summarise(across(everything(), list(
      count = ~sum(!is.na(.)),
      mean = ~round(mean(., na.rm = TRUE), round_digits),
      sd = ~round(sd(., na.rm = TRUE), round_digits),
      min = ~round(min(., na.rm = TRUE), round_digits),
      q25 = ~round(quantile(., 0.25, na.rm = TRUE), round_digits),
      median = ~round(median(., na.rm = TRUE), round_digits),
      q75 = ~round(quantile(., 0.75, na.rm = TRUE), round_digits),
      max = ~round(max(., na.rm = TRUE), round_digits)
    ), .names = "{.col}_{.fn}")) %>%
    pivot_longer(cols = everything(),
                 names_to = c("Variable", ".value"),
                 names_sep = "_")
  
  # Step 3: Merge + final polish
  summary_table <- left_join(missing_summary, summary_stats, by = "Variable") %>%
    mutate(
      Action = case_when(
        Missing_Percent > 80 ~ "Drop (>80% missing)",
        Missing_Percent > 0 ~ "Consider imputing",
        TRUE ~ "Keep"
      ),
      MaxFlag = ifelse(!is.na(max) & max > 2, "Check coding (>2)", "")
    ) %>%
    arrange(desc(Missing_Percent)) %>%
    rename(`Missing %` = Missing_Percent)
  
  return(summary_table)
}


# function for categorical data

view_categorical_labels <- function(data) {
  cat_vars <- names(data)[sapply(data, function(x) {
    is.factor(x) || is.character(x) || ("labels" %in% names(attributes(x)))
  })]
  
  for (var in cat_vars) {
    cat("\n============================\n")
    cat("ðŸ“Œ Variable:", var, "\n")
    
    var_data <- data[[var]]

    # Show value labels if exist
    label_attr <- attributes(var_data)$labels
    if (!is.null(label_attr)) {
      cat("ðŸ”– Value Labels:\n")
      print(label_attr)
    }
    
    # Show levels if factor or character
    if (is.factor(var_data) || is.character(var_data)) {
      cat("ðŸ“Š Levels / Unique Values:\n")
      print(levels(as.factor(var_data)))
    }

    # Frequency Table using as_factor for haven_labelled
    cat("ðŸ“ˆ Frequency Table:\n")
    freq_table <- table(as_factor(var_data), useNA = "ifany")
    print(freq_table)

    # Auto-check for suspicious codes
    suspicious_codes <- c(8, 9, 88, 99, 888, 999, 8888, 9999)
    numeric_data <- suppressWarnings(as.numeric(as.character(var_data)))
    invalids <- intersect(suspicious_codes, unique(na.omit(numeric_data)))
    
    if (length(invalids) > 0) {
      cat("ðŸš¨ Warning: Suspicious codes detected -> ", paste(invalids, collapse = ", "), "\n")
    }
  }
}
```

```{r}
# Summarize the dataset via the functions

summary_data1 <- summarize_data_quality(data1)

# View it
View(summary_data1)

# categorical data
view_categorical_labels(data1)
```

A structured summary of missingness and descriptive statistics was generated using custom functions. Categorical variables were inspected for value label inconsistencies, while numeric variables were assessed for completeness and distribution.

Several variables, such as `dm`, `hpt`, `ckd`, and `smoker`, contained suspicious codes (e.g., 8) representing non-standard or unknown values, which required recoding.

Based on this analysis, variables with high missingness or problematic coding were excluded from the final model.

## Cleaning the problematic dataset for analysis (select variables that already been re-coded appropriately)

```{r}
library(dplyr)

# Create cleaned dataset
data2 <- data1 %>%
  select(
    time2, status3b, age2, sex3, hpt2cat, dm2cat, dyslipid2cat,
    referral2cat, icd10cat3
  )

glimpse(data2)
```

A cleaned dataset (`data2`) was created by selecting only variables that had already been appropriately recoded.

The chosen variables were `time2`, `status3b` (event indicator), `age2`, `sex3`, `hpt2cat`, `dm2cat`, `dyslipid2cat`, `referral2cat`, and `icd10cat3`.

This step ensured the inclusion of well-defined, binary or categorical predictors and improved the quality and interpretability of the analysis.

## Summarizing and visualising the cleaned dataset

```{r}
# Run the summarize function

summary_data2 <- summarize_data_quality(data2)

# View it
View(summary_data2)

view_categorical_labels(data2)
```

```{r}
library(ggplot2)
library(dplyr)
library(forcats)

# Barplot : status3b

data2 %>%
  mutate(
    status3b = case_when(
      status3b == 0 ~ "Alive",
      status3b == 1 ~ "Dead",
      TRUE ~ NA_character_
    )
  ) %>%
  ggplot(aes(x = status3b, fill = status3b)) +
  geom_bar() +
  labs(title = "Distribution of Survival Status",
       x = "Status at Discharge", y = "Count") +
  theme_minimal() +
  scale_fill_manual(values = c("Alive" = "#4CAF50", "Dead" = "#F44336"))
```

```{r}
# Barplot : sex

data2 %>%
  mutate(sex3 = factor(sex3, levels = c(0,1), labels = c("Female", "Male"))) %>%
  ggplot(aes(x = sex3, fill = sex3)) +
  geom_bar() +
  labs(title = "Sex Distribution", x = "Sex", y = "Count") +
  theme_minimal() +
  scale_fill_manual(values = c("#FF69B4", "#2196F3"))
```

```{r}
# Barplot : icd10cat3

data2 %>%
  mutate(icd10cat3 = factor(icd10cat3,
                            levels = c(0,1,2),
                            labels = c("Cerebral Ischaemia", "SAH", "ICB/Others"))) %>%
  ggplot(aes(x = icd10cat3, fill = icd10cat3)) +
  geom_bar() +
  labs(title = "Stroke Subtype Distribution", x = "Stroke Type", y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")
```

```{r}
# Barplot : referral2cat

data2 %>%
  mutate(referral2cat = factor(referral2cat,
                               levels = c(0, 1),
                               labels = c("Hospital", "GP/Home/Missing"))) %>%
  ggplot(aes(x = referral2cat, fill = referral2cat)) +
  geom_bar() +
  labs(title = "Referral Source", x = "Referral Category", y = "Count") +
  theme_minimal() +
  scale_fill_manual(values = c("#03A9F4", "#FFC107"))
```

Descriptive statistics and frequency tables were produced for the cleaned dataset.

Among the 226 patients, 53 deaths were observed (23.5%). The majority were females (57.1%) and had cerebral ischaemic stroke. Most referrals originated from home or private clinics (61.5%).

These characteristics provided an overview of the study population before proceeding with model fitting.

## Convert the cleaned data to appropriate types

```{r}
data3 <- data2 %>%
  mutate(
    status3b = as.numeric(zap_labels(status3b)), 
    sex3 = as.factor(sex3),
    hpt2cat = as.factor(hpt2cat),
    dm2cat = as.factor(dm2cat),
    dyslipid2cat = as.factor(dyslipid2cat),
    referral2cat = as.factor(referral2cat),
    icd10cat3 = as.factor(icd10cat3)
  )

```

Prior to modeling, variables were converted to appropriate types.

Categorical variables were converted to factors and the outcome variable (status3b) was transformed into a numeric binary indicator (0 = alive, 1 = dead). This is essential for ensuring compatibility with the Cox proportional hazards model.

## Create Survival Object

```{r}
surv_obj <- Surv(time = data3$time2, event = data3$status3b)
```

A survival object was created using the `Surv()` function, which combines the time-to-event (`time2`) and event status (`status3b`) variables.

This served as the basis for fitting the semiparametric Cox model and for plotting survival curves.

## Fit Cox Proportional Hazard Model (Semi-parametic)

```{r}
cox_model <- coxph(surv_obj ~ age2 + sex3 + hpt2cat + dm2cat + dyslipid2cat + referral2cat + icd10cat3, data = data3)
summary(cox_model)

```

The Cox proportional hazards model was fitted using the cleaned dataset (data3). The following interpretations are based on the model output:

-   **Age** was significantly associated with increased hazard of death (HR = 1.028; 95% CI: 1.005â€“1.051; *p* = 0.016), indicating that each additional year of age raised the hazard by approximately 2.8%.

-   **Stroke subtype (icd10cat3)** showed borderline significant results. Patients with subarachnoid hemorrhage (SAH) or intracerebral bleeding had approximately twice the hazard of death compared to those with cerebral ischemia or other types:

-   SAH (HR = 2.13; 95% CI: 0.91â€“5.00; *p* = 0.081)

-   ICB/Others (HR = 2.06; 95% CI: 0.99â€“4.28; *p* = 0.052)

<!-- -->

-   Other variables such as **sex**, **hypertension**, **diabetes**, **dyslipidemia**, and **referral source** did not show statistically significant associations with survival.

-   Overall, the model demonstrated acceptable discrimination (concordance index = 0.739), and global tests (Likelihood Ratio, Wald, and Score) were statistically significant, indicating a good model fit.

## Check Proportional Hazard Assumption

```{r}
cox.zph(cox_model)
```

-   Variables such as **diabetes (dm2cat)** (*p* = 0.031), **referral source (referral2cat)** (*p* = 0.004), and **stroke type (icd10cat3)** (*p* = 0.008) violated the assumption, suggesting that their effects on the hazard of death may vary over time. Need to be addressed in further advance modelling.

-   The **global test** was borderline significant (*p* = 0.0506), further supporting the need to consider alternative modeling strategies such as stratification or time-varying covariates for those variables.

## Plot survival curves by Sex

```{r}
ggsurvplot(
  survfit(surv_obj ~ sex3, data = data3),
  data = data3,
  pval = TRUE,
  conf.int = TRUE,
  risk.table = TRUE,
  legend.labs = c("Male", "Female")
)
```

Kaplan-Meier survival curves were plotted by sex.

Although males appeared to have slightly better survival, the log-rank test indicated that the difference was not statistically significant (*p* = 0.17).

This visual representation complements the Cox model finding, which also did not show a significant effect of sex on survival outcome.

## Predict Survival for a Hypothetical Patient

```{r}
library(survival)
library(survminer)

predict_survival_plot <- function(model, data, patient_profile, conf.int = TRUE, title = "Predicted Survival Curve") {
  # Ensure all factor variables are matched to model's data
  vars <- names(patient_profile)

  for (var in vars) {
    if (is.factor(data[[var]])) {
      patient_profile[[var]] <- factor(patient_profile[[var]], levels = levels(data[[var]]))
    }
  }

  # Predict survival
  surv_pred <- survfit(model, newdata = patient_profile)

  # Plot survival curve
  ggsurvplot(
    surv_pred,
    data = patient_profile,
    conf.int = conf.int,
    legend.title = "Hypothetical Patient",
    ggtheme = theme_minimal(),
    title = title
  )
}

```

```{r}
# Create patient profile
my_patient <- data.frame(
  age2 = 65,
  sex3 = "1",
  hpt2cat = "1",
  dm2cat = "1",
  dyslipid2cat = "0",
  referral2cat = "1",
  icd10cat3 = "1"
)

# Call the function
predict_survival_plot(cox_model, data3, my_patient, conf.int = TRUE)
```

A personalized survival curve was generated for a hypothetical patient: a **65-year-old male** diagnosed with **subarachnoid hemorrhage (SAH)**, with a history of **hypertension and diabetes**, no dyslipidemia, and referred from **home or a private clinic**. This profile was chosen to reflect a higher-risk stroke case within the dataset.

Based on the fitted Cox proportional hazards model, the predicted survival probabilities over time were estimated as follows:

Day 5: **92%**

Day 10: **85%**

Day 15: **76%**

Day 20: **65%**

Day 30: **48%**

Day 45: **30%**

Day 60: **15%**

These estimates indicate a gradual decline in survival probability over time, with a particularly steep drop beyond day 20. By day 30, the patientâ€™s survival probability is already below 50%, highlighting the urgency of clinical attention in such cases.

Hence, the establishment of this surival semiparametric model enables **individualized prognostic insights** tailored to a patientâ€™s profile, which can supports **clinical decision-making** and priority setting, especially for follow-up care or palliative discussions. Besides, it also can enhances **patientâ€“clinician communication** by providing quantifiable risk trajectories. In conclusion, it can provide a valuable tool for **evidence-based, patient-centered care** in stroke management itself.
